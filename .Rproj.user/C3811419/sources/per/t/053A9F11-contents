---
title: "Untitled"
author: "Sean Ng"
date: "12/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
theme_set(theme_light())
library(drlib)
library(broom)
library(rvest)
library(tidytext)
```

```{r}
ramen <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv")
```

```{r}
glimpse(ramen)
```

```{r}
ramen_processed <- ramen %>% 
  mutate(style = fct_lump(style, 4),
         country = fct_lump(country, 12),
         brand = fct_lump(brand, 20)) %>% 
  replace_na(list(style = "Other")) %>% 
  mutate(brand = fct_relevel(brand, "Other"),
         country = fct_relevel(country, "Other"),
         style = fct_relevel(style, "Pack"))
  
ramen_processed %>% 
  pivot_longer(cols = -c(review_number, stars), names_to = "category", values_to = "value") %>% 
  count(category, value) %>% 
  group_by(category) %>% 
  top_n(20, n) %>% 
  ungroup() %>% 
  mutate(value = reorder_within(value, n, category)) %>% 
  ggplot(aes(x = value, y = n)) +
  geom_col() +
  facet_wrap(~ category, scales = "free_y") +
  scale_x_reordered() +
  coord_flip()
```

```{r}
ramen %>% count(variety, sort = TRUE)
```

```{r}
lm(stars ~ brand + country + style, ramen_processed) %>% 
  tidy(conf.int = TRUE) %>% 
  filter(term != "(Intercept)") %>% 
  arrange(desc(estimate)) %>% 
  extract(term, c("category", "term"), "^([a-z]+)([A-Z].*)") %>% 
  mutate(term = fct_reorder(term, estimate)) %>% 
  ggplot(aes(x = estimate, y = term, colour = category)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +
  geom_vline(lty = 2, xintercept = 0) +
  facet_wrap(~ category, ncol = 1, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "Estimated effect on ramne rating",
       y = "",
       title = "Coefficients that predict ramen ratings",
       subtitle = "Less common brands and countries were lumped together as the reference level") 
```

```{r}
ramen_processed %>% 
  filter(!is.na(stars)) %>% 
  unnest_tokens(word, variety) %>% 
  group_by(word) %>% 
  summarise(avg_rating = mean(stars, na.rm = TRUE),
            n = n()) %>% 
  arrange(desc(avg_rating)) %>% 
  filter(n > 9)
  
```

```{r}
review_links <- 
  read_html("https://web.archive.org/web/20190531065107/https://www.theramenrater.com/resources-2/the-list/") %>% 
  html_nodes("#myTable a")

reviews <- tibble(review_number = parse_number(html_text(review_links)),
                  link = html_attr(review_links, "href"))



```

# maybe try this again with a date closer to his so the review numbers match with the dataset 

```{r}
page <- read_html("https://www.theramenrater.com/2019/05/23/3180-yum-yum-moo-deng/")

get_review_text <- function(url) {
  message(url)
  
  read_html(url) %>% 
  html_nodes(".entry-content > p") %>% 
  html_text() %>% 
  str_subset(".")
}
  
review_text <- reviews %>% 
  head(250) %>% 
  mutate(text = map(link, possibly(get_review_text, character(0), quiet = FALSE)))
 

```

```{r}
review_paragraphs <- review_text %>% 
  fiilter(!map_lgl(text, is.null)) %>% 
  unnest() %>% 
  filter(str_detect(text, "Finished")) %>% 
  mutate(text = str_remove(text, "Finished.*?\\. "))

review_paragraphs %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = "word") %>% 
  filter(str_detect(word, "[a-z]")) %>% 
  count(word, sort = TRUE)

```

