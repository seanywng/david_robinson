---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(scales)
library(lubridate)
theme_set(theme_light())

library(tidymodels)
library(textrecipes)
library(stacks)
```

```{r}
mset <- metric_set(rmse)

grid_control <- control_grid(save_pred = TRUE, 
                             save_workflow = TRUE, 
                             extract = extract_model)
```

### data cleaning

```{r}

extract_json_names <- function(s) {
  str_match_all(s, "'name': '(.*?)'") %>% 
    map(~. [, 2]) %>% 
    map_chr(paste, collapse = ";")
}

clean_data <-  function(tbl) {
  tbl %>%
    rename(keywords = Keywords) %>%
    mutate(across(c(belongs_to_collection, genres, production_companies, production_countries, spoken_languages, 
                  keywords, cast, crew), 
                extract_json_names)) %>%
    mutate(has_homepage = !is.na(homepage),
         release_date = mdy(release_date), 
         release_date = if_else(release_date >= "2020-01-01",
                               release_date - years(100), 
                               release_date))
}

```


```{r}
data <- read_csv("./box_office/train.csv") %>% 
  clean_data() %>% 
  mutate(revenue = log2(revenue))

holdout <-read_csv("./box_office/test.csv") %>% 
  clean_data()

sample <- read_csv("./box_office/sample_submission.csv") 
# what are we predicting?
colnames(sample)

set.seed(2021)
spl <- initial_split(data, prop = 0.75)
train <- training(spl)
test <- testing(spl)

train_fold <- train %>% 
  vfold_cv(v = 5)

set.seed(2021-06-08)
train_5fold <- train %>% vfold_cv(v = 5)

glimpse(sample)
```

### EDA

```{r}



train %>% 
  filter(budget > 1000) %>% 
  ggplot(aes(budget, revenue)) + 
  geom_point() + 
  scale_x_log10(labels = dollar) +
  scale_y_log10(labels = dollar)

train %>% 
  mutate(genres = extract_json_names(genres),
         belongs_to_collection = extract_json_names(belongs_to_collection))
  
  
  mutate(genres = str_replace_all(genres, "'", '"')) %>% 
  filter(!is.na(genres)) %>% 
  mutate(genres = map(genres, jsonlite::fromJSON)) 

train %>% sample_n(10) %>% pull(genres)


summarise_revenue <- function(tbl) {
  tbl %>%
    summarise(median_revenue = median(2 ^ revenue),
              geom_mean_revenue = exp(mean(log(2 ^ revenue))),
              n = n()) %>% 
    arrange(desc(n))
}

train %>% 
  group_by(original_language = fct_lump(original_language, 10)) %>% 
  summarise_revenue() %>% 
  mutate(original_language = fct_reorder(original_language, median_revenue)) %>% 
  ggplot(aes(x = median_revenue, y = original_language)) + 
  geom_point(aes(size = n)) + 
  scale_x_continuous(labels = dollar)

train %>% 
  ggplot(aes(x = runtime, y = revenue)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  scale_x_log10() + 
  scale_y_log10(labels = dollar)

glimpse(train)
  
```

```{r}
train %>% 
  #group_by(year = year(release_date)) %>%
  group_by(year = 5 * year(release_date) %/% 5) %>% 
  summarise_revenue() %>% 
  filter(n >= 20) %>% 
  ggplot(aes(x = year, y = median_revenue)) +
  geom_line() +
  geom_point(aes(size = n)) +
  expand_limits(y = 0)

train %>% arrange(desc(release_date)) %>% pull(release_date)

train %>% 
  group_by(month = month(release_date, label = TRUE),
           year =  10 * year(release_date) %/% 10) %>% 
  filter(year >= 1980) %>% 
  summarise_revenue() %>% 
  ggplot(aes(x = month, y = median_revenue, colour = factor(year))) + 
  geom_line(aes(group = year)) + 
  scale_y_continuous(labels = dollar) + 
  expand_limits(y = 0)

train %>% 
  group_by(week = week(release_date)) %>% 
  summarise_revenue() %>% 
  ggplot(aes(x = week, y = median_revenue)) + 
  geom_line(group = 1) + 
  scale_y_continuous(labels = dollar) + 
  expand_limits(y = 0)
  

```


### ML

Numeric predictors: budger, runtime, popularity, all log +1 budget (might be NA)
Categorial predictors: genres, production companies, production countries, spoken languages, keywords, cast, crew
Text: original title, overview, tagline, title, original title
date_time : time of year

```{r}
train %>% 
  separate_rows(genres, sep = ";") %>% 
  group_by(genres) %>% 
  summarise_revenue() %>% 
  mutate(genres = fct_reorder(genres, median_revenue)) %>%  
  ggplot(aes(x = median_revenue, y = genres)) + 
  geom_point(aes(size = n)) + 
  geom_text(aes(label = n, vjust = 1, hjust = 1)) +
  scale_x_continuous(labels = comma)
```



```{r}
lin_rec <- recipe(revenue ~ budget + runtime + popularity + 
                    release_date + 
                    original_language + 
                    genres + production_companies + production_countries + spoken_languages + cast + crew + keywords,
                  data = train) %>%
  step_log(runtime, popularity, budget, base = 2, offset = 1) %>% 
  step_mutate(release_year = year(release_date),
              release_week = week(release_date)) %>% 
  step_impute_mean(runtime) %>%
  step_other(original_language, threshold = 0.01) %>% 
  step_tokenize(genres, production_companies, production_countries, 
                spoken_languages, cast, crew, keywords, 
                token = "regex", options = list(pattern = ";")) %>%
  step_tokenfilter(genres, min_times = 5, max_tokens = 20) %>%
  step_tokenfilter(production_companies, production_countries, 
                spoken_languages, cast, crew, keywords, 
                min_times = 20) %>% 
  step_tf(genres, production_companies, production_countries,
          spoken_languages, cast, crew, keywords) %>% 
  # tokenise the natural language
  step_tokenize(overview, tagline, title) %>% 
  step_stopwords(overview, tagline, title) %>% 
  step_tokenfilter(overview, tagline, title, min_times = 50) %>% 
  step_tf(overview, tagline, title) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_ns(release_year, deg_free = 2) %>% 
  step_ns(release_week, deg_free = 6) %>% 
  step_rm(release_date)

lin_wf <- workflow() %>% 
  add_recipe(lin_rec) %>% 
  add_model(linear_reg(penalty = tune()) %>% set_engine("glmnet"))

lin_tune <- lin_wf %>% 
  tune_grid(train_5fold,
            metrics = mset, 
            control = grid_control,
            grid = crossing(penalty = 10^ seq(-7, -0.5, 0.1)))

lin_tune %>% autoplot()

```

```{r}
lin_rec %>% 
  prep() %>% 
  juice()
```

