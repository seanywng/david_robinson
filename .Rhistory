w_digs = w_p1_tot_digs + w_p2_tot_digs,
l_attacks = l_p1_tot_attacks + l_p2_tot_attacks,
l_kills = l_p1_tot_kills + l_p2_tot_kills,
l_errors = l_p1_tot_errors + l_p1_tot_errors,
l_aces = l_p1_tot_aces + l_p2_tot_aces,
l_blocks = l_p1_tot_blocks + l_p2_tot_blocks,
l_serrve_errors = l_p1_tot_serve_errors + l_p2_tot_serve_errors,
l_blocks = l_p1_tot_blocks + l_p2_tot_blocks,
l_digs = l_p1_tot_digs + l_p2_tot_digs,
) %>%
na.omit()
vb_parsed
vb_parsed <- vb_matches %>%
transmute(
circuit,
gender,
year,
w_attacks = w_p1_tot_attacks + w_p2_tot_attacks,
w_kills = w_p1_tot_kills + w_p2_tot_kills,
w_errors = w_p1_tot_errors + w_p1_tot_errors,
w_aces = w_p1_tot_aces + w_p2_tot_aces,
w_blocks = w_p1_tot_blocks + w_p2_tot_blocks,
w_serve_errors = w_p1_tot_serve_errors + w_p2_tot_serve_errors,
w_blocks = w_p1_tot_blocks + w_p2_tot_blocks,
w_digs = w_p1_tot_digs + w_p2_tot_digs,
l_attacks = l_p1_tot_attacks + l_p2_tot_attacks,
l_kills = l_p1_tot_kills + l_p2_tot_kills,
l_errors = l_p1_tot_errors + l_p1_tot_errors,
l_aces = l_p1_tot_aces + l_p2_tot_aces,
l_blocks = l_p1_tot_blocks + l_p2_tot_blocks,
l_serve_errors = l_p1_tot_serve_errors + l_p2_tot_serve_errors,
l_blocks = l_p1_tot_blocks + l_p2_tot_blocks,
l_digs = l_p1_tot_digs + l_p2_tot_digs,
) %>%
na.omit()
vb_parsed %>%
select(circuit, gender, year,
w_attacks:w_digs) %>%
rename_with(~ str_remove_all(., "w_"),
w_attacks:w_digs)
winners <- vb_parsed %>%
select(circuit, gender, year,
w_attacks:w_digs) %>%
rename_with(~str_remove_all(., "w_"),
w_attacks:w_digs) %>%
mutate(win = "win")
losers <- vb_parsed %>%
select(circuit, gender, year,
l_attacks:l_digs) %>%
rename_with(~str_remove_all(., "l_"),
l_attacks:l_digs) %>%
mutate(win = "lose")
vb_df <- bind_rows(
winners,
losers
) %>%
mutate_if(is.character, factor)
vb_df <- bind_rows(winners, losers) %>%
mutate_if(is.character, factor)
vb_df <- bind_rows(
vb_parsed %>%
select(circuit, gender, year,
w_attacks:w_digs) %>%
rename_with( ~ str_remove_all(., "w_"),
w_attacks:w_digs) %>%
mutate(win = "win"),
vb_parsed %>%
select(circuit, gender, year,
l_attacks:l_digs) %>%
rename_with( ~ str_remove_all(., "l_"),
l_attacks:l_digs) %>%
mutate(win = "lose")
) %>%
mutate_if(is.character, factor)
vb_df %>%
pivot_longer(attacks:digs,
names_to = "stat",
values_to = "value")
vb_df %>%
pivot_longer(attacks:digs,
names_to = "stat",
values_to = "value") %>%
ggplot(aes(x = gender,
y = value,
fill = win)) +
geom_boxplot() +
facet_wrap(~stat, scales = "free_y")
vb_df %>%
pivot_longer(attacks:digs,
names_to = "stat",
values_to = "value") %>%
ggplot(aes(x = gender,
y = value,
colour = win)) +
geom_boxplot(alpha = .4) +
facet_wrap(~stat,
scales = "free_y",
nrow = 2) +
labs(y = "",
colour = "",
fill = "")
vb_df %>%
pivot_longer(attacks:digs,
names_to = "stat",
values_to = "value") %>%
ggplot(aes(x = gender,
y = value,
colour = win,
fill = win)) +
geom_boxplot(alpha = .4) +
facet_wrap(~stat,
scales = "free_y",
nrow = 2) +
labs(y = "",
colour = "",
fill = "")
vb_split <- initial_split(vb_df, strata = win)
library(tidymodels)
vb_split <- initial_split(vb_df, strata = win)
train <- training(vb_split)
test <- testing(vb_split)
xgb_spec <- boost_tree(
trees = 1000,
tree_depth = tune(),
min_n = tune(),
loss_reduction = tune(),
sample_size = tune(),
# How much randomness is included in the model
mtry = tune(),
learn_rate = tune()
) %>%
set_engine("xgboost") %>%
set_mode("classification")
xgb_grid <- grid_latin_hypercube(
tree_depth(),
min_n(),
loss_reduction(),
sample_size = sample_prop(),
# You need to give it the training data as it doesn't know what the max number of predictors is
finalize(mtry(), vb_train),
learn_rate(),
# You usually want to go higher than 20
size = 20
)
xgb_grid <- grid_latin_hypercube(
tree_depth(),
min_n(),
loss_reduction(),
sample_size = sample_prop(),
# You need to give it the training data as it doesn't know what the max number of predictors is
finalize(mtry(), train),
learn_rate(),
# You usually want to go higher than 20
size = 20
)
xgb_wf <- workflow %>%
add_formula(win ~ .) %>%
add_model(xgb_spec)
xgb_wf <- workflow() %>%
add_formula(win ~ .) %>%
add_model(xgb_spec)
set.seed(123)
vb_folds <- vfold_cv(train, strata = win)
doParallel::registerDoParallel()
set.seed(234)
xgb_res <- tune_grid(
xgb_wf,
resamples = vb_folds,
grid = xgb_grid,
control = control_grid(save_pred = TRUE)
)
xgb_res
xgb_res
xgb_res %>%
collect_metrics()
xgb_res %>%
collect_metrics() %>%
filter(.metric == "roc_auc") %>%
select(mean, mtry:sample_size) %>%
pivot_longer(cols = mtry:sample_size,
names_to = "parameter",
values_to = "value") %>%
ggplot(aes(x = value,
y = mean,
colour = parameter)) +
geom_point(show.legend = FALSE) +
facet_wrap(~parameter, scales = "free_x")
# show_best shows the 5 best models
show_best(xgb_res, "roc_auc")
# For better results, it would be best to increase the size in the construction of the latin hypercube grid
# If not, you will be limited by "auto-generated" values
best_auc <- select_best(xgb_res, "roc_auc")
final_xgb <- finalize_workflow((wgb_wf, best_auc))
final_xgb <- finalize_workflow((xgb_wf, best_auc))
final_xgb <- finalize_workflow(xgb_wf, best_auc)
final_xgb
library(vip)
final_xgb %>%
fit(data = train) %>%
pull_workflow_fit() %>%
vip(geom = "point")
final_res <- last_fit(final_xgb, vb_split)
final_res %>% collect_metrics()
# These are predictions on the testing data
# Meaning that we can do things like confusion matrices
final_res %>%
collect_predictions() %>%
conf_mat(win, .pred_class)
final_res %>%
collect_predictions() %>%
roc_curve(win, .pred_win) %>%
autoplot()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(scales)
theme_set(theme_light())
water_raw <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-05-04/water.csv")
glimpse(water_raw)
?coord_fixed
water_raw %>%
filter(status_id %in% c("y", "n") &
country_name == "Sierra Leone" &
lat_deg > 0 &
lat_deg < 15 &
lon_deg <0) %>%
ggplot(aes(x = lon_deg,
y = lat_deg,
colour = status_id)) +
geom_point(alpha = .2) +
coord_fixed() +
guides(colour = guide_legend(overide.aes = list(alpha = 1)))
water_raw %>%
filter(status_id %in% c("y", "n") &
country_name == "Sierra Leone" &
lat_deg > 0 &
lat_deg < 15 &
lon_deg <0) %>%
ggplot(aes(x = lon_deg,
y = lat_deg,
colour = status_id)) +
geom_point(alpha = .15) +
coord_fixed() +
guides(colour = guide_legend(overide.aes = list(alpha = 1)))
water_raw %>%
filter(status_id %in% c("y", "n") &
country_name == "Sierra Leone" &
lat_deg > 0 &
lat_deg < 15 &
lon_deg <0) %>%
ggplot(aes(x = lon_deg,
y = lat_deg,
colour = status_id)) +
geom_point(alpha = .15) +
coord_fixed() +
guides(color = guide_legend(overide.aes = list(alpha = 1)))
water_raw %>%
filter(status_id %in% c("y", "n") &
country_name == "Sierra Leone" &
lat_deg > 0 &
lat_deg < 15 &
lon_deg <0) %>%
ggplot(aes(x = lon_deg,
y = lat_deg,
colour = status_id)) +
geom_point(alpha = .15) +
coord_fixed() +
guides(colour = guide_legend(override.aes = list(alpha = 1)))
water <- water_raw %>%
filter(status_id %in% c("y", "n") &
country_name == "Sierra Leone" &
lat_deg > 0 &
lat_deg < 15 &
lon_deg <0)
water <- water_raw %>%
filter(status_id %in% c("y", "n") &
country_name == "Sierra Leone" &
lat_deg > 0 &
lat_deg < 15 &
lon_deg <0) %>%
select(-country_name, -status, -report_date)
water %>% count(pay)
water %>% count(water_tech)
water %>% count(water_source)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytuesdayR)
library(scales)
library(lubridate)
theme_set(theme_light())
clean_data <- . %>%
select(-timestamp) %>%
mutate(date = ymd(date))
image_alt <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/image_alt.csv') %>%
clean_data()
color_contrast <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/color_contrast.csv') %>%
clean_data()
ally_scores <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/ally_scores.csv') %>%
clean_data()
bytes_total <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/bytes_total.csv') %>%
clean_data()
speed_index <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/speed_index.csv') %>%
clean_data()
speed_index %>% glimpse()
speed_index %>%
ggplot(aes(x = date, y = p50, colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25, ymax = p75), alpha = .25) +
labs(y = "Median speed (with 25th-75th percentiles")
image_alt %>%
ggplot(aes(x = date, y = percent,
colour = client)) +
geom_line() +
labs(y = "% of images with alt text")
color_contrast %>%
ggplot(aes(x = date, y = percent,
colour = client)) +
geom_line() +
labs(y = "% of images with colour contrast [?]")
ally_scores %>%
ggplot(aes(x = date, y = p50,
colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25, ymax = p75),
alpha = .25)
ally_scores %>%
ggplot(aes(x = date, y = p50,
colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25, ymax = p75),
alpha = .25) +
labs(y = "Median accessibility scores (with 25th-75th percentiles)")
ally_scores %>%
ggplot(aes(x = date, y = p50,
colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25, ymax = p75),
alpha = .25) +
labs(y = "Median a11y scores (with 25th-75th percentiles)")
combined <- bind_rows(
speed_index,
bytes_total,
ally_scores
)
combined %>%
ggplot(aes(x = date,
y = p50,
colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25,
ymax = p75),
alpha = .25) +
facet_wrap(~ measure) +
labs(y = "Median (with 25th-75th percentiles)")
combined %>%
ggplot(aes(x = date,
y = p50,
colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25,
ymax = p75),
alpha = .25) +
facet_wrap(~ measure,
scale = "free_y") +
labs(y = "Median (with 25th-75th percentiles)")
combined %>%
ggplot(aes(x = date,
y = p50,
colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25,
ymax = p75),
alpha = .25) +
facet_wrap(~ measure,
scale = "free") +
labs(y = "Median (with 25th-75th percentiles)")
combined %>%
ggplot(aes(x = date,
y = p50,
colour = client)) +
geom_line() +
geom_ribbon(aes(ymin = p25,
ymax = p75),
alpha = .15) +
facet_wrap(~ measure,
scale = "free") +
labs(y = "Median (with 25th-75th percentiles)")
bind_rows(image_alt, color_contrast) %>%
ggplot(aes(x = date, y = percent,
colour = client)) +
geom_line() +
scale_y_continuous(labels = percent_format()) +
labs(y = "Percentage") +
facet_wrap(~ measure)
bind_rows(image_alt, color_contrast) %>%
ggplot(aes(x = date, y = percent / 100,
colour = client)) +
geom_line() +
scale_y_continuous(labels = percent_format()) +
labs(y = "Percentage") +
facet_wrap(~ measure)
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
url <- "https://en.wikipedia.org/wiki/World_Happiness_Report"
read_html(url) %>%
html_element("table.wikitable") %>%
html_table()
url = "https://en.wikipedia.org/wiki/World_Happiness_Report"
read_html(url) %>%
html_element("table.wikitable") %>%
html_table()
read_html(url) %>%
html_element('table.wikitable') %>%
html_table()
read_html(url) %>%
html_element('.wikitable') %>%
html_table()
read_html(url) %>%
html_element('table') %>%
html_table()
read_html(url) %>%
html_element('.table') %>%
html_table()
read_html(url) %>%
html_element("mw_collapsiple") %>%
html_table()
read_html(url) %>%
html_element("mw_collapsible") %>%
html_table()
read_html(url) %>%
html_element("table.mw") %>%
html_table()
read_html(url) %>%
html_element(".wikitable") %>%
html_table()
url <-  "https://raw.githack.com/ccs-amsterdam/r-course-material/master/miscellaneous/simple_html.html"
read_html(url)
read_html(url) %>%
html_element("#exampleTable") %>%
html_table()
read_html(url) %>%
html_element("#steve") %>%
html_table()
read_html(url) %>%
html_element(".someTable") %>%
html_table()
read_html(url) %>%
html_elements(".someTable") %>%
html_table()
read_html(url) %>%
html_element("#exampleTable")
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
url <-  "https://raw.githack.com/ccs-amsterdam/r-course-material/master/miscellaneous/simple_html.html"
# Hashes are important when filling in an ID name
read_html(url) %>%
html_element("#exampleTable") %>%
html_table()
read_html(url) %>%
html_element("#steve") %>%
html_table()
'https://en.wikipedia.org/wiki/Hyperlink' %>%
read_html() %>%
html_elements('a') %>%
length()
'https://en.wikipedia.org/wiki/Hyperlink' %>%
read_html() %>%
html_elements('# content a') %>%
length()
'https://en.wikipedia.org/wiki/Hyperlink' %>%
read_html() %>%
html_elements('#content a') %>%
length()
'https://en.wikipedia.org/wiki/Hyperlink' %>%
read_html() %>%
html_elements('a') %>%
length()
'https://en.wikipedia.org/wiki/Hyperlink' %>%
read_html() %>%
html_elements('a')
'https://en.wikipedia.org/wiki/Hyperlink' %>%
read_html() %>%
html_elements('a') %>%
html_attr("href")
'https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29' %>%
read_html() %>%
html_elements('a') %>%
html_attr("href")
list <- 'https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29' %>%
read_html() %>%
html_elements('a') %>%
html_attr("href")
list
df <- 'https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29' %>%
read_html() %>%
html_elements('a') %>%
html_attr("href") %>%
as.tibble()
df
df <- 'https://reliefweb.int/updates?advanced-search=%28PC241%29_%28F10%29' %>%
read_html() %>%
html_elements('a') %>%
html_attr("href") %>%
as_tibble() %>%
filter(str_detect(value, "https://"))
df
html <-  read_html('https://www.imdb.com/name/nm0000195/')
name_overview <- html %>%
html_element('#name-overview-widget')
html_text2(name_overview)
